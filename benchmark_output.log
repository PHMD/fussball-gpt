
[94m================================================================================[0m
[94m  GERMAN LANGUAGE MODEL BENCHMARK[0m
[94m  Testing 12 models √ó 4 categories = 48 test cases[0m
[94m================================================================================[0m

[96müìä Fetching fresh sports data...[0m
Fetching data from all sources...
Fetched 6 news articles and 10 sports events
[92m‚úÖ Sports data loaded[0m


[95m================================================================================[0m
[95müìù Category: Short-Form Q&A (German Fluency Baseline)[0m
[95m================================================================================[0m

[96m[ANTHROPIC][0m
  [1/48] [93m  Testing: Claude Sonnet 4.5 on Short-Form Q&A (German Fluency Baseline)...[0m [92m‚úÖ 4458ms[0m
  [2/48] [93m  Testing: Claude Haiku 4.5 on Short-Form Q&A (German Fluency Baseline)...[0m [92m‚úÖ 2318ms[0m

[96m[OPENAI][0m
  [3/48] [93m  Testing: GPT-5 on Short-Form Q&A (German Fluency Baseline)...[0m [92m‚úÖ 12157ms[0m
  [4/48] [93m  Testing: GPT-5 Mini on Short-Form Q&A (German Fluency Baseline)...[0m [92m‚úÖ 12217ms[0m
  [5/48] [93m  Testing: GPT-5 Nano on Short-Form Q&A (German Fluency Baseline)...[0m [92m‚úÖ 12296ms[0m
  [6/48] [93m  Testing: GPT-5 Chat on Short-Form Q&A (German Fluency Baseline)...[0m [92m‚úÖ 1256ms[0m

[96m[MISTRAL][0m
  [7/48] [93m  Testing: Mistral Large on Short-Form Q&A (German Fluency Baseline)...[0m [92m‚úÖ 3086ms[0m
  [8/48] [93m  Testing: Mistral Medium on Short-Form Q&A (German Fluency Baseline)...[0m [92m‚úÖ 3728ms[0m
  [9/48] [93m  Testing: Mistral Small on Short-Form Q&A (German Fluency Baseline)...[0m [92m‚úÖ 641ms[0m

[96m[SILICONFLOW][0m
  [10/48] [93m  Testing: Qwen 2.5 72B on Short-Form Q&A (German Fluency Baseline)...[0m [92m‚úÖ 3539ms[0m
  [11/48] [93m  Testing: Qwen 2.5 14B on Short-Form Q&A (German Fluency Baseline)...[0m [92m‚úÖ 3729ms[0m
  [12/48] [93m  Testing: Llama 3.1 8B on Short-Form Q&A (German Fluency Baseline)...[0m [92m‚úÖ 1017ms[0m


[95m================================================================================[0m
[95müìù Category: Long-Form Editorial Synthesis[0m
[95m================================================================================[0m

[96m[ANTHROPIC][0m
  [13/48] [93m  Testing: Claude Sonnet 4.5 on Long-Form Editorial Synthesis...[0m [92m‚úÖ 16398ms[0m
  [14/48] [93m  Testing: Claude Haiku 4.5 on Long-Form Editorial Synthesis...[0m [92m‚úÖ 10177ms[0m

[96m[OPENAI][0m
  [15/48] [93m  Testing: GPT-5 on Long-Form Editorial Synthesis...[0m [92m‚úÖ 17381ms[0m
  [16/48] [93m  Testing: GPT-5 Mini on Long-Form Editorial Synthesis...[0m [92m‚úÖ 16814ms[0m
  [17/48] [93m  Testing: GPT-5 Nano on Long-Form Editorial Synthesis...[0m [92m‚úÖ 14065ms[0m
  [18/48] [93m  Testing: GPT-5 Chat on Long-Form Editorial Synthesis...[0m [92m‚úÖ 12481ms[0m

[96m[MISTRAL][0m
  [19/48] [93m  Testing: Mistral Large on Long-Form Editorial Synthesis...[0m [92m‚úÖ 15857ms[0m
  [20/48] [93m  Testing: Mistral Medium on Long-Form Editorial Synthesis...[0m [92m‚úÖ 27614ms[0m
  [21/48] [93m  Testing: Mistral Small on Long-Form Editorial Synthesis...[0m [92m‚úÖ 6161ms[0m

[96m[SILICONFLOW][0m
  [22/48] [93m  Testing: Qwen 2.5 72B on Long-Form Editorial Synthesis...[0m [92m‚úÖ 24812ms[0m
  [23/48] [93m  Testing: Qwen 2.5 14B on Long-Form Editorial Synthesis...[0m [92m‚úÖ 17103ms[0m
  [24/48] [93m  Testing: Llama 3.1 8B on Long-Form Editorial Synthesis...[0m [92m‚úÖ 12271ms[0m


[95m================================================================================[0m
[95müìù Category: Multi-Turn Agent Conversation[0m
[95m================================================================================[0m

[96m[ANTHROPIC][0m
  [25/48] [93m  Testing: Claude Sonnet 4.5 on Multi-Turn Agent Conversation...[0m [92m‚úÖ 6617ms[0m
  [26/48] [93m  Testing: Claude Haiku 4.5 on Multi-Turn Agent Conversation...[0m [92m‚úÖ 4212ms[0m

[96m[OPENAI][0m
  [27/48] [93m  Testing: GPT-5 on Multi-Turn Agent Conversation...[0m [92m‚úÖ 10500ms[0m
  [28/48] [93m  Testing: GPT-5 Mini on Multi-Turn Agent Conversation...[0m [92m‚úÖ 9423ms[0m
  [29/48] [93m  Testing: GPT-5 Nano on Multi-Turn Agent Conversation...[0m [92m‚úÖ 9957ms[0m
  [30/48] [93m  Testing: GPT-5 Chat on Multi-Turn Agent Conversation...[0m [92m‚úÖ 7053ms[0m

[96m[MISTRAL][0m
  [31/48] [93m  Testing: Mistral Large on Multi-Turn Agent Conversation...[0m [92m‚úÖ 13647ms[0m
  [32/48] [93m  Testing: Mistral Medium on Multi-Turn Agent Conversation...[0m [92m‚úÖ 11762ms[0m
  [33/48] [93m  Testing: Mistral Small on Multi-Turn Agent Conversation...[0m [92m‚úÖ 733ms[0m

[96m[SILICONFLOW][0m
  [34/48] [93m  Testing: Qwen 2.5 72B on Multi-Turn Agent Conversation...[0m [92m‚úÖ 12206ms[0m
  [35/48] [93m  Testing: Qwen 2.5 14B on Multi-Turn Agent Conversation...[0m [92m‚úÖ 3661ms[0m
  [36/48] [93m  Testing: Llama 3.1 8B on Multi-Turn Agent Conversation...[0m [92m‚úÖ 2732ms[0m


[95m================================================================================[0m
[95müìù Category: Real-Time Data Grounding (RAG Test)[0m
[95m================================================================================[0m

[96m[ANTHROPIC][0m
  [37/48] [93m  Testing: Claude Sonnet 4.5 on Real-Time Data Grounding (RAG Test)...[0m [92m‚úÖ 12688ms[0m
  [38/48] [93m  Testing: Claude Haiku 4.5 on Real-Time Data Grounding (RAG Test)...[0m [92m‚úÖ 5079ms[0m

[96m[OPENAI][0m
  [39/48] [93m  Testing: GPT-5 on Real-Time Data Grounding (RAG Test)...[0m [92m‚úÖ 16051ms[0m
  [40/48] [93m  Testing: GPT-5 Mini on Real-Time Data Grounding (RAG Test)...[0m [92m‚úÖ 11101ms[0m
  [41/48] [93m  Testing: GPT-5 Nano on Real-Time Data Grounding (RAG Test)...[0m [92m‚úÖ 12161ms[0m
  [42/48] [93m  Testing: GPT-5 Chat on Real-Time Data Grounding (RAG Test)...[0m [92m‚úÖ 7767ms[0m

[96m[MISTRAL][0m
  [43/48] [93m  Testing: Mistral Large on Real-Time Data Grounding (RAG Test)...[0m [92m‚úÖ 12662ms[0m
  [44/48] [93m  Testing: Mistral Medium on Real-Time Data Grounding (RAG Test)...[0m [92m‚úÖ 9224ms[0m
  [45/48] [93m  Testing: Mistral Small on Real-Time Data Grounding (RAG Test)...[0m [92m‚úÖ 4588ms[0m

[96m[SILICONFLOW][0m
  [46/48] [93m  Testing: Qwen 2.5 72B on Real-Time Data Grounding (RAG Test)...[0m [92m‚úÖ 20584ms[0m
  [47/48] [93m  Testing: Qwen 2.5 14B on Real-Time Data Grounding (RAG Test)...[0m [92m‚úÖ 5846ms[0m
  [48/48] [93m  Testing: Llama 3.1 8B on Real-Time Data Grounding (RAG Test)...[0m [92m‚úÖ 9239ms[0m


[92m================================================================================[0m
[92m‚úÖ Benchmark complete! 48 tests run[0m
[92m================================================================================[0m

[92müíæ Results saved to: results/benchmark_results.json[0m

[94m================================================================================[0m
[94m  BENCHMARK SUMMARY[0m
[94m================================================================================[0m

[92mSuccess Rate: 100.0% (48/48)[0m

[96mAverage Response Time by Model:[0m
  Mistral Small               3031ms
  Claude Haiku 4.5            5446ms
  Llama 3.1 8B                6315ms
  GPT-5 Chat                  7139ms
  Qwen 2.5 14B                7585ms
  Claude Sonnet 4.5          10040ms
  Mistral Large              11313ms
  GPT-5 Nano                 12120ms
  GPT-5 Mini                 12389ms
  Mistral Medium             13082ms
  GPT-5                      14022ms
  Qwen 2.5 72B               15285ms

[93mToken Usage & Cost Estimate:[0m
  Total Input Tokens:  50,050
  Total Output Tokens: 26,423
  Estimated Cost:      ~$0.29

[94m================================================================================[0m

[92m‚úÖ Full results saved to: results/benchmark_results.json[0m
[96mNext: Review responses and generate quality analysis[0m

